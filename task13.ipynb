{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "from sim_class import Simulation\n",
    "\n",
    "class OT2Env(gym.Env):\n",
    "    def __init__(self, render=True, max_steps=1000):\n",
    "        super(OT2Env, self).__init__()\n",
    "        self.render_enabled = render  # Use render_enabled to track rendering\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        # Create the simulation environment\n",
    "        self.sim = Simulation(num_agents=1, render=self.render_enabled)\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(low=np.array([-1, -1, -1, 0]), high=np.array([1, 1, 1, 1]), shape=(4,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(6,), dtype=np.float32)\n",
    "        # keep track of the number of steps\n",
    "        self.steps = 0\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        # being able to set a seed is required for reproducibility\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Reset the state of the environment to an initial state\n",
    "        # set a random goal position for the agent, consisting of x, y, and z coordinates within the working area (you determined these values in the previous datalab task)\n",
    "        # ['-0.18700', '0.21950', '0.16950']\n",
    "        # ['0.25300', '-0.17050', '0.16940']\n",
    "        # ['0.25300', '-0.17050', '0.28950']\n",
    "        # ['-0.18700', '0.21950', '0.28950']\n",
    "        # ['-0.18700', '-0.17050', '0.16950']\n",
    "        # ['0.25300', '0.21950', '0.16950']\n",
    "        # ['0.25300', '0.21950', '0.28950']\n",
    "        # ['-0.18700', '-0.17050', '0.28950']\n",
    "\n",
    "        self.goal_position = np.array([\n",
    "            np.random.uniform(-0.18700, 0.25300),\n",
    "            np.random.uniform(-0.17050, 0.21950),\n",
    "            np.random.uniform(0.16940, 0.28950)\n",
    "        ], dtype=np.float32)\n",
    "        # Call the environment reset function\n",
    "        observation = self.sim.reset(num_agents=1)\n",
    "        #print(observation)\n",
    "        # now we need to process the observation and extract the relevant information, the pipette position, convert it to a numpy array, and append the goal position and make sure the array is of type np.float32    \n",
    "        #{'robotId_2': {'joint_states': {'joint_0': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_1': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}, 'joint_2': {'position': 0.0, 'velocity': 0.0, 'reaction_forces': (0.0, 0.0, 0.0, 0.0, 0.0, 0.0), 'motor_torque': 0.0}}, 'robot_position': [0.0, 0.0, 0.03], 'pipette_position': [0.073, 0.0895, 0.1195]}}\n",
    "        pipette_position = np.array(observation[f'robotId_{self.sim.robotIds[0]}']['pipette_position'], dtype=np.float32)\n",
    "\n",
    "        observation = np.concatenate([pipette_position, self.goal_position], axis=0)\n",
    "\n",
    "        # Reset the number of steps\n",
    "        self.steps = 0\n",
    "\n",
    "        return observation, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        # since we are only controlling the pipette position, we accept 3 values for the action and need to append 0 for the drop action\n",
    "        action = np.append(action, 0)\n",
    "\n",
    "        # Call the environment step function\n",
    "        observation = self.sim.run([action]) # Why do we need to pass the action as a list? Think about the simulation class.\n",
    "        # now we need to process the observation and extract the relevant information, the pipette position, convert it to a numpy array, and append the goal position and make sure the array is of type np.float32\n",
    "        pipette_position = np.array(observation[f'robotId_{self.sim.robotIds[0]}']['pipette_position'], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        observation = np.concatenate([pipette_position, self.goal_position], axis=0)\n",
    "        # Calculate the reward, this is something that you will need to experiment with to get the best results\n",
    "        reward = float(-np.linalg.norm(pipette_position - self.goal_position)) # we can use the L2 norm to calculate the distance between the pipette position and the goal position\n",
    "        \n",
    "        # next we need to check if the if the task has been completed and if the episode should be terminated\n",
    "        # To do this we need to calculate the distance between the pipette position and the goal position and if it is below a certain threshold, we will consider the task complete. \n",
    "        # What is a reasonable threshold? Think about the size of the pipette tip and the size of the plants.\n",
    "        distance = np.linalg.norm(pipette_position - self.goal_position)\n",
    "        if distance < 0.05:\n",
    "            terminated = True\n",
    "            # we can also give the agent a positive reward for completing the task\n",
    "            reward = float(100)\n",
    "        else:\n",
    "            terminated = False\n",
    "\n",
    "        # next we need to check if the episode should be truncated, we can check if the current number of steps is greater than the maximum number of steps\n",
    "        if self.steps >= self.max_steps:\n",
    "            truncated = True\n",
    "        else:\n",
    "            truncated = False\n",
    "\n",
    "        info = {} # we don't need to return any additional information\n",
    "\n",
    "        # increment the number of steps\n",
    "        self.steps += 1\n",
    "\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "    \n",
    "    def close(self):\n",
    "        self.sim.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "Step 1:\n",
      "  Current Position: [0.0735 0.0889 0.1205]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 281.61 mm\n",
      "Step 2:\n",
      "  Current Position: [0.0744 0.0878 0.1224]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 279.80 mm\n",
      "Step 3:\n",
      "  Current Position: [0.0757 0.0862 0.1253]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 277.16 mm\n",
      "Step 4:\n",
      "  Current Position: [0.0776 0.0839 0.1291]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 273.45 mm\n",
      "Step 5:\n",
      "  Current Position: [0.0799 0.0811 0.1333]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 269.07 mm\n",
      "Step 6:\n",
      "  Current Position: [0.0826 0.0778 0.1405]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 263.58 mm\n",
      "Step 7:\n",
      "  Current Position: [0.0858 0.0739 0.1464]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 257.67 mm\n",
      "Step 8:\n",
      "  Current Position: [0.0895 0.0697 0.1511]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 251.49 mm\n",
      "Step 9:\n",
      "  Current Position: [0.0936 0.0656 0.1551]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 245.33 mm\n",
      "Step 10:\n",
      "  Current Position: [0.0978 0.0614 0.1591]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 239.07 mm\n",
      "Step 11:\n",
      "  Current Position: [0.1019 0.0572 0.1629]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 232.94 mm\n",
      "Step 12:\n",
      "  Current Position: [0.1061 0.0531 0.1667]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 226.88 mm\n",
      "Step 13:\n",
      "  Current Position: [0.1103 0.0489 0.1703]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 220.81 mm\n",
      "Step 14:\n",
      "  Current Position: [0.1144 0.0447 0.1739]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 214.85 mm\n",
      "Step 15:\n",
      "  Current Position: [0.1186 0.0406 0.1773]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 208.99 mm\n",
      "Step 16:\n",
      "  Current Position: [0.1228 0.0364 0.1806]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 203.09 mm\n",
      "Step 17:\n",
      "  Current Position: [0.1269 0.0322 0.1839]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 197.31 mm\n",
      "Step 18:\n",
      "  Current Position: [0.1311 0.0281 0.187 ]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 191.63 mm\n",
      "Step 19:\n",
      "  Current Position: [0.1351 0.0239 0.19  ]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 186.02 mm\n",
      "Step 20:\n",
      "  Current Position: [0.139  0.0197 0.193 ]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 180.52 mm\n",
      "Step 21:\n",
      "  Current Position: [0.1427 0.0156 0.1958]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 175.26 mm\n",
      "Step 22:\n",
      "  Current Position: [0.1464 0.0114 0.1985]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 169.97 mm\n",
      "Step 23:\n",
      "  Current Position: [0.1499 0.0072 0.2012]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 164.85 mm\n",
      "Step 24:\n",
      "  Current Position: [0.1533 0.0031 0.2037]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 159.90 mm\n",
      "Step 25:\n",
      "  Current Position: [ 0.1565 -0.0011  0.2061]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 155.02 mm\n",
      "Step 26:\n",
      "  Current Position: [ 0.1597 -0.0053  0.2084]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 150.18 mm\n",
      "Step 27:\n",
      "  Current Position: [ 0.1628 -0.0094  0.2106]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 145.53 mm\n",
      "Step 28:\n",
      "  Current Position: [ 0.1657 -0.0136  0.2128]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 140.95 mm\n",
      "Step 29:\n",
      "  Current Position: [ 0.1686 -0.0178  0.2148]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 136.40 mm\n",
      "Step 30:\n",
      "  Current Position: [ 0.1713 -0.0219  0.2167]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 132.08 mm\n",
      "Step 31:\n",
      "  Current Position: [ 0.174  -0.0261  0.2186]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 127.73 mm\n",
      "Step 32:\n",
      "  Current Position: [ 0.1765 -0.0303  0.2203]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 123.50 mm\n",
      "Step 33:\n",
      "  Current Position: [ 0.179  -0.0344  0.2219]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 119.40 mm\n",
      "Step 34:\n",
      "  Current Position: [ 0.1813 -0.0386  0.2235]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 115.37 mm\n",
      "Step 35:\n",
      "  Current Position: [ 0.1836 -0.0428  0.2249]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 111.35 mm\n",
      "Step 36:\n",
      "  Current Position: [ 0.1858 -0.0469  0.2263]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 107.54 mm\n",
      "Step 37:\n",
      "  Current Position: [ 0.1879 -0.0511  0.2275]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 103.70 mm\n",
      "Step 38:\n",
      "  Current Position: [ 0.1899 -0.0553  0.2287]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 99.98 mm\n",
      "Step 39:\n",
      "  Current Position: [ 0.1918 -0.0594  0.2297]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 96.39 mm\n",
      "Step 40:\n",
      "  Current Position: [ 0.1937 -0.0636  0.2307]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 92.80 mm\n",
      "Step 41:\n",
      "  Current Position: [ 0.1955 -0.0678  0.2316]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 89.32 mm\n",
      "Step 42:\n",
      "  Current Position: [ 0.1971 -0.0719  0.2324]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 86.04 mm\n",
      "Step 43:\n",
      "  Current Position: [ 0.1988 -0.076   0.2331]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 82.77 mm\n",
      "Step 44:\n",
      "  Current Position: [ 0.2003 -0.0799  0.2337]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 79.78 mm\n",
      "Step 45:\n",
      "  Current Position: [ 0.2018 -0.0836  0.2342]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 76.98 mm\n",
      "Step 46:\n",
      "  Current Position: [ 0.2032 -0.0872  0.2346]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 74.33 mm\n",
      "Step 47:\n",
      "  Current Position: [ 0.2045 -0.0907  0.235 ]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 71.88 mm\n",
      "Step 48:\n",
      "  Current Position: [ 0.2058 -0.0941  0.2353]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 69.54 mm\n",
      "Step 49:\n",
      "  Current Position: [ 0.207  -0.0974  0.2355]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 67.34 mm\n",
      "Step 50:\n",
      "  Current Position: [ 0.2081 -0.1005  0.2356]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 65.32 mm\n",
      "Step 51:\n",
      "  Current Position: [ 0.2092 -0.1035  0.2357]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 63.45 mm\n",
      "Step 52:\n",
      "  Current Position: [ 0.2103 -0.1065  0.2357]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 61.61 mm\n",
      "Step 53:\n",
      "  Current Position: [ 0.2113 -0.1093  0.2356]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 59.92 mm\n",
      "Step 54:\n",
      "  Current Position: [ 0.2122 -0.112   0.2355]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 58.40 mm\n",
      "Step 55:\n",
      "  Current Position: [ 0.2131 -0.1147  0.2353]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 56.90 mm\n",
      "Step 56:\n",
      "  Current Position: [ 0.2139 -0.1172  0.2351]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 55.60 mm\n",
      "Step 57:\n",
      "  Current Position: [ 0.2147 -0.1197  0.2348]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 54.31 mm\n",
      "Step 58:\n",
      "  Current Position: [ 0.2155 -0.122   0.2345]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 53.17 mm\n",
      "Step 59:\n",
      "  Current Position: [ 0.2162 -0.1243  0.2341]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 52.05 mm\n",
      "Step 60:\n",
      "  Current Position: [ 0.2169 -0.1265  0.2337]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 51.04 mm\n",
      "Step 61:\n",
      "  Current Position: [ 0.2175 -0.1287  0.2332]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 50.05 mm\n",
      "Step 62:\n",
      "  Current Position: [ 0.2181 -0.1307  0.2327]\n",
      "  Goal Position: [ 0.23040123 -0.13578124  0.18536073]\n",
      "  Distance to Goal: 49.17 mm\n",
      "Environment Terminated!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO  # Replace PPO with your RL algorithm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = \"C:\\\\Users\\\\jarro\\\\Documents\\\\GitHub\\\\Reinforcement learning\\\\model.zip\"  # Replace with the actual path to your model\n",
    "\n",
    "# Load the trained model\n",
    "model = PPO.load(model_path)  # Replace PPO with the correct algorithm\n",
    "\n",
    "# Initialize the environment\n",
    "env = OT2Env(render=False)  # Initialize the environment with rendering disabled\n",
    "\n",
    "# Test the trained model\n",
    "def test_model(env, model, max_steps=1000):\n",
    "    \"\"\"\n",
    "    Test the trained model to move the pipette to the target location.\n",
    "\n",
    "    Args:\n",
    "        env: The testing environment.\n",
    "        model: The trained RL model.\n",
    "        max_steps: Maximum number of steps for the test.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Reset the environment\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    print(f\"Goal Position: {env.goal_position}\")\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Predict the action for the current state\n",
    "        action, _ = model.predict(obs, deterministic=True)  # Use deterministic=True for testing\n",
    "        obs, _, terminated, truncated, _ = env.step(action)  # Execute the action\n",
    "\n",
    "        # Calculate the accuracy (distance to the goal) in mm\n",
    "        current_position = obs[:3]  # Extract the current position from the observation\n",
    "        goal_position = env.goal_position\n",
    "        distance_to_goal = np.linalg.norm(goal_position - current_position) * 1000  # Convert to mm\n",
    "\n",
    "        # Print debug information\n",
    "        print(f\"Step {step + 1}:\")\n",
    "        print(f\"  Current Position: {current_position}\")\n",
    "        print(f\"  Goal Position: {goal_position}\")\n",
    "        print(f\"  Distance to Goal: {distance_to_goal:.2f} mm\")\n",
    "\n",
    "        # Check if the goal is reached or the environment signals termination\n",
    "        if terminated or distance_to_goal <= 1.0:  # 1 mm accuracy requirement\n",
    "            print(\"Goal Reached!\" if distance_to_goal <= 1.0 else \"Environment Terminated!\")\n",
    "            break\n",
    "\n",
    "    # Close the environment\n",
    "    env.close()\n",
    "\n",
    "\n",
    "# Run the test\n",
    "if __name__ == \"__main__\":\n",
    "    test_model(env, model, max_steps=1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "block_2B_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
